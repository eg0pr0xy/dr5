0001: 
0002: import React, { useState, useEffect, useRef } from 'react';
0003: 
0004: interface MemoryFragment {
0005:   x: number;
0006:   y: number;
0007:   content: string;
0008:   opacity: number;
0009:   life: number;
0010:   isVibrating: boolean;
0011: }
0012: 
0013: interface MemoryModeProps {
0014:   audioContext: AudioContext;
0015:   isAnimated?: boolean;
0016: }
0017: 
0018: const MemoryMode: React.FC<MemoryModeProps> = ({ audioContext, isAnimated }) => {
0019:   const [fragments, setFragments] = useState<MemoryFragment[]>([]);
0020:   const [ambientRms, setAmbientRms] = useState(0);
0021:   const rmsRef = useRef(0);
0022:   const [statusText, setStatusText] = useState("ROOM_IS_EMPTY");
0023:   const [cutoff, setCutoff] = useState(800);
0024:   const [q, setQ] = useState(5.0);
0025:   const [currentStep, setCurrentStep] = useState(0);
0026:   const [ghostsActive, setGhostsActive] = useState(true);
0027:   const [pipsActive, setPipsActive] = useState(true);
0028:   const [droneActive, setDroneActive] = useState(true);
0029:   const [diag, setDiag] = useState<{ bufFill: number; grainRate: number; rms: number; lastGhost: string }>({ bufFill: 0, grainRate: 0, rms: 0, lastGhost: '--:--:--' });
0030:   // Touch field state
0031:   const [touchActive, setTouchActive] = useState(false);
0032:   const [tilt, setTilt] = useState(0); // -1..1
0033:   const [density, setDensity] = useState(0.5); // 0..1
0034:   const [widthMs, setWidthMs] = useState(160); // grain width in ms
0035:   const pinchStartDistRef = useRef<number | null>(null);
0036:   const pinchStartWidthRef = useRef<number>(160);
0037:   const fieldRectRef = useRef<DOMRect | null>(null);
0038: 
0039:   const engineRef = useRef<{
0040:     micStream: MediaStream | null;
0041:     processor: ScriptProcessorNode | null;
0042:     ringBuffer: AudioBuffer;
0043:     ringData: Float32Array;
0044:     bufferPtr: number;
0045:     capturedSamples: number;
0046:     mainGain: GainNode;
0047:     droneFilter: BiquadFilterNode;
0048:     droneGain: GainNode;
0049:     staticGain: GainNode;
0050:     dustGain: GainNode;
0051:     grainsGain: GainNode;
0052:     windowCurve: Float32Array;
0053:     tiltLow: BiquadFilterNode;
0054:     tiltHigh: BiquadFilterNode;
0055:     scheduler: {
0056:       timer: number | null;
0057:       lookahead: number;
0058:       intervalMs: number;
0059:       nextTime: number;
0060:       grainDur: number;
0061:       targetRate: number;
0062:       ghostUntil: number;
0063:       userDensity: number; // 0..1
0064:     };
0065:   } | null>(null);
0066: 
0067:   const lastStepTimeRef = useRef<number>(0);
0068:   const stepIndexRef = useRef<number>(0);
0069:   const CAGE_FRAGMENTS = ["4'33\"", "SILENCE", "EVENT", "CHANCE", "ROOM", "EMPTY", "I_CHING", "MUSHROOM", "DECAY", "LISTEN"];
0070:   const FREQ_STEPS = [400, 800, 1200, 300, 2000, 600, 1600, 100];
0071:   const Q_STEPS = [2, 12, 5, 25, 4, 40, 8, 1];
0072: 
0073:   useEffect(() => {
0074:     const bufferSize = Math.floor(audioContext.sampleRate * 4); // 4s rolling buffer
0075:     const ringBuffer = audioContext.createBuffer(1, bufferSize, audioContext.sampleRate);
0076:     const ringData = ringBuffer.getChannelData(0);
0077:     ringData.fill(0);
0078:     let ptr = 0;
0079:     let capturedSamples = 0;
0080: 
0081:     const mainGain = audioContext.createGain();
0082:     mainGain.gain.setValueAtTime(0.5, audioContext.currentTime);
0083:     mainGain.connect(audioContext.destination);
0084:     const droneFilter = audioContext.createBiquadFilter();
0085:     droneFilter.type = 'bandpass';
0086:     const staticFilter = audioContext.createBiquadFilter();
0087:     staticFilter.type = 'highpass';
0088:     staticFilter.frequency.setValueAtTime(4500, audioContext.currentTime);
0089:     const staticGain = audioContext.createGain();
0090:     const dustGain = audioContext.createGain();
0091:     const noiseBuffer = audioContext.createBuffer(1, audioContext.sampleRate * 2, audioContext.sampleRate);
0092:     const noiseData = noiseBuffer.getChannelData(0);
0093:     for (let i = 0; i < noiseData.length; i++) noiseData[i] = Math.random() * 2 - 1;
0094:     const noiseSource = audioContext.createBufferSource();
0095:     noiseSource.buffer = noiseBuffer; noiseSource.loop = true;
0096:     const dustSource = audioContext.createBufferSource();
0097:     const dustBuffer = audioContext.createBuffer(1, audioContext.sampleRate * 4, audioContext.sampleRate);
0098:     const dustData = dustBuffer.getChannelData(0);
0099:     for (let i = 0; i < dustData.length; i++) if (Math.random() > 0.9997) dustData[i] = (Math.random()*2-1)*0.4;
0100:     dustSource.buffer = dustBuffer; dustSource.loop = true;
0101:     const droneGain = audioContext.createGain();
0102:     noiseSource.connect(droneFilter); droneFilter.connect(droneGain); droneGain.connect(mainGain);
0103:     noiseSource.connect(staticFilter); staticFilter.connect(staticGain); staticGain.connect(mainGain);
0104:     dustSource.connect(dustGain); dustGain.connect(mainGain);
0105: 
0106:     // Grains output chain
0107:     const grainsGain = audioContext.createGain();
0108:     grainsGain.gain.setValueAtTime(0.35, audioContext.currentTime);
0109:     // Spectral tilt filters (low/high shelf)
0110:     const tiltLow = audioContext.createBiquadFilter();
0111:     tiltLow.type = 'lowshelf';
0112:     tiltLow.frequency.setValueAtTime(500, audioContext.currentTime);
0113:     tiltLow.gain.setValueAtTime(0, audioContext.currentTime);
0114:     const tiltHigh = audioContext.createBiquadFilter();
0115:     tiltHigh.type = 'highshelf';
0116:     tiltHigh.frequency.setValueAtTime(4000, audioContext.currentTime);
0117:     tiltHigh.gain.setValueAtTime(0, audioContext.currentTime);
0118:     grainsGain.connect(tiltLow);
0119:     tiltLow.connect(tiltHigh);
0120:     tiltHigh.connect(mainGain);
0121: 
0122:     // Precompute Hann window curve
0123:     const grainDur = 0.16; // seconds (updated by pinch)
0124:     const windowSamples = Math.max(128, Math.floor(audioContext.sampleRate * 0.16));
0125:     const windowCurve = new Float32Array(windowSamples);
0126:     for (let i = 0; i < windowSamples; i++) {
0127:       windowCurve[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / (windowSamples - 1)));
0128:     }
0129: 
0130:     noiseSource.start(); dustSource.start();
0131: 
0132:     let micStream: MediaStream | null = null;
0133:     let processor: ScriptProcessorNode | null = null;
0134:     let intervalId: number | null = null;
0135:     let diagIvId: number | null = null;
0136:     let ghostId: number | null = null;
0137:     const startRecording = async () => {
0138:       try {
0139:         micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
0140:         const source = audioContext.createMediaStreamSource(micStream);
0141:         processor = audioContext.createScriptProcessor(4096, 1, 1);
0142:         processor.onaudioprocess = (e) => {
0143:           const input = e.inputBuffer.getChannelData(0);
0144:           for (let i = 0; i < input.length; i++) {
0145:             ringData[ptr] = input[i];
0146:             ptr = (ptr + 1) % bufferSize;
0147:             if (capturedSamples < bufferSize) capturedSamples++;
0148:           }
0149:           let sum = 0; for (let i = 0; i < input.length; i++) sum += input[i] * input[i];
0150:           const rms = Math.sqrt(sum / input.length); setAmbientRms(rms); rmsRef.current = rms;
0151:         };
0152:         source.connect(processor); processor.connect(audioContext.destination); 
0153:         const scheduler = { timer: null as number | null, lookahead: 0.08, intervalMs: 25, nextTime: audioContext.currentTime + 0.05, grainDur, targetRate: 10, ghostUntil: 0, userDensity: density };
0154:         engineRef.current = { micStream, processor, ringBuffer, ringData, bufferPtr: ptr, capturedSamples, mainGain, droneFilter, droneGain, staticGain, dustGain, grainsGain, windowCurve, tiltLow, tiltHigh, scheduler };
0155: 
0156:         // Grain scheduler with lookahead
0157:         const scheduleGrain = (when: number) => {
0158:           if (!engineRef.current) return;
0159:           const ctx = audioContext;
0160:           const { ringBuffer: rb, grainsGain: gGain, windowCurve: win } = engineRef.current;
0161:           const sr = ctx.sampleRate;
0162:           const dur = engineRef.current.scheduler.grainDur;
0163:           const bufLenSec = rb.length / sr;
0164:           const filledSec = Math.min(engineRef.current.capturedSamples, rb.length) / sr;
0165:           const biasRecent = 0.35;
0166:           const isGhost = when < engineRef.current.scheduler.ghostUntil;
0167:           const bias = isGhost ? 0.8 : biasRecent;
0168:           const recentSpan = Math.max(0.1, Math.min(filledSec, 1.2));
0169:           const randBack = Math.random() * recentSpan;
0170:           const startBack = bias * randBack + (1 - bias) * (Math.random() * (filledSec || 0.1));
0171:           let startSec = (engineRef.current.bufferPtr / sr) - startBack;
0172:           while (startSec < 0) startSec += bufLenSec;
0173:           while (startSec >= bufLenSec) startSec -= bufLenSec;
0174: 
0175:           const src = ctx.createBufferSource();
0176:           src.buffer = rb;
0177:           const env = ctx.createGain();
0178:           env.gain.setValueAtTime(0, when);
0179:           env.gain.setValueCurveAtTime(win, when, dur);
0180:           src.connect(env);
0181:           env.connect(gGain);
0182:           try {
0183:             src.start(when, startSec, Math.min(dur, bufLenSec - 0.001));
0184:             src.stop(when + dur + 0.01);
0185:           } catch {}
0186:         };
0187: 
0188:         const tick = () => {
0189:           if (!engineRef.current) return;
0190:           const ctx = audioContext;
0191:           const sched = engineRef.current.scheduler;
0192:           engineRef.current.bufferPtr = ptr;
0193:           engineRef.current.capturedSamples = capturedSamples;
0194:           const baseRate = 4 + Math.min(0.5, Math.max(0, rmsRef.current)) * 40;
0195:           const userTarget = 4 + (sched.userDensity * 28);
0196:           const blended = baseRate * 0.6 + userTarget * 0.4;
0197:           sched.targetRate = Math.min(32, blended + (ctx.currentTime < sched.ghostUntil ? 8 : 0));
0198:           const period = 1 / Math.max(1, sched.targetRate);
0199:           while (sched.nextTime < ctx.currentTime + sched.lookahead) {
0200:             scheduleGrain(sched.nextTime);
0201:             sched.nextTime += period;
0202:           }
0203:         };
0204:         intervalId = window.setInterval(tick, engineRef.current.scheduler.intervalMs);
0205: 
0206:         // Ghost events
0207:         const formatTimeHMS = (t: number) => {
0208:           const d = new Date(t);
0209:           const p = (n: number) => n.toString().padStart(2, '0');
0210:           return `${p(d.getHours())}:${p(d.getMinutes())}:${p(d.getSeconds())}`;
0211:         };
0212:         const scheduleGhost = () => {
0213:           if (!engineRef.current) return;
0214:           const now = audioContext.currentTime;
0215:           const dur = 0.6 + Math.random() * 0.9;
0216:           engineRef.current.scheduler.ghostUntil = now + dur;
0217:           setDiag(prev => ({ ...prev, lastGhost: formatTimeHMS(Date.now()) }));
0218:           ghostId = window.setTimeout(scheduleGhost, 8000 + Math.random() * 12000) as unknown as number;
0219:         };
0220:         if (ghostsActive) ghostId = window.setTimeout(scheduleGhost, 5000 + Math.random() * 8000) as unknown as number;
0221: 
0222:         // Diagnostics updater
0223:         diagIvId = window.setInterval(() => {
0224:           if (!engineRef.current) return;
0225:           const fill = Math.min(1, engineRef.current.capturedSamples / bufferSize);
0226:           const bufFill = Math.round(fill * 100);
0227:           const grainRate = Math.round(engineRef.current.scheduler.targetRate);
0228:           const rms = Number(ambientRms.toFixed(3));
0229:           setDiag(prev => ({ ...prev, bufFill, grainRate, rms }));
0230:         }, 500);
0231:         const scheduleNextEvent = () => {
0232:           if (!engineRef.current) return;
0233:           const time = audioContext.currentTime;
0234:           if (time - lastStepTimeRef.current > 1.5) {
0235:             lastStepTimeRef.current = time;
0236:             stepIndexRef.current = (stepIndexRef.current + 1) % FREQ_STEPS.length;
0237:             engineRef.current.droneFilter.frequency.setTargetAtTime(FREQ_STEPS[stepIndexRef.current], time, 0.02);
0238:             engineRef.current.droneFilter.Q.setTargetAtTime(Q_STEPS[stepIndexRef.current], time, 0.02);
0239:             setCutoff(FREQ_STEPS[stepIndexRef.current]); setQ(Q_STEPS[stepIndexRef.current]); setCurrentStep(stepIndexRef.current);
0240:           }
0241:           setTimeout(scheduleNextEvent, 400 + Math.random() * 2000);
0242:         };
0243:         scheduleNextEvent();
0244:       } catch (err) { setStatusText("ERR:MIC_MISSING"); }
0245:     };
0246:     startRecording();
0247:     return () => {
0248:       if (micStream) micStream.getTracks().forEach(t => t.stop());
0249:       if (processor) processor.disconnect();
0250:       if (intervalId) window.clearInterval(intervalId);
0251:       if (diagIvId) window.clearInterval(diagIvId);
0252:       if (ghostId) window.clearTimeout(ghostId);
0253:       noiseSource.stop(); dustSource.stop(); mainGain.disconnect();
0254:     };
0255:   }, [audioContext, ghostsActive, pipsActive]);
0256: 
0257:   useEffect(() => {
0258:     const interval = setInterval(() => {
0259:       setFragments(prev => {
0260:         const decayed = prev.map(f => ({ ...f, life: f.life - 1, opacity: f.opacity * 0.94 })).filter(f => f.life > 0);
0261:         if (Math.random() > 0.75) {
0262:           decayed.push({ x: Math.floor(Math.random() * 80) + 10, y: Math.floor(Math.random() * 80) + 10, content: CAGE_FRAGMENTS[Math.floor(Math.random() * CAGE_FRAGMENTS.length)], opacity: 1, life: 8 + Math.random() * 12, isVibrating: false });
0263:         }
0264:         return decayed;
0265:       });
0266:     }, 600);
0267:     return () => clearInterval(interval);
0268:   }, []);
0269: 
0270:   const motionClass = isAnimated ? 'animate-ui-motion' : '';
0271: 
0272:   // Touch handlers for field interaction
0273:   const onTouchStart: React.TouchEventHandler<HTMLDivElement> = (e) => {
0274:     setTouchActive(true);
0275:     fieldRectRef.current = (e.currentTarget as HTMLDivElement).getBoundingClientRect();
0276:     if (e.touches.length === 2) {
0277:       const dx = e.touches[1].clientX - e.touches[0].clientX;
0278:       const dy = e.touches[1].clientY - e.touches[0].clientY;
0279:       pinchStartDistRef.current = Math.hypot(dx, dy);
0280:       pinchStartWidthRef.current = widthMs;
0281:     }
0282:   };
0283: 
0284:   const onTouchMove: React.TouchEventHandler<HTMLDivElement> = (e) => {
0285:     if (!fieldRectRef.current) fieldRectRef.current = (e.currentTarget as HTMLDivElement).getBoundingClientRect();
0286:     const rect = fieldRectRef.current;
0287:     if (e.touches.length === 1) {
0288:       const t = e.touches[0];
0289:       const nx = (t.clientX - rect.left) / rect.width; // 0..1
0290:       const ny = (t.clientY - rect.top) / rect.height; // 0..1
0291:       const newTilt = Math.max(-1, Math.min(1, (nx - 0.5) * 2));
0292:       const newDensity = Math.max(0, Math.min(1, 1 - ny));
0293:       setTilt(newTilt);
0294:       setDensity(newDensity);
0295:       if (engineRef.current) {
0296:         // Update spectral tilt filters smoothly
0297:         const tctx = (engineRef.current.mainGain.context as AudioContext);
0298:         const g = newTilt * 9; // +/-9 dB
0299:         engineRef.current.tiltLow.gain.setTargetAtTime(g, tctx.currentTime, 0.08);
0300:         engineRef.current.tiltHigh.gain.setTargetAtTime(-g, tctx.currentTime, 0.08);
0301:         engineRef.current.scheduler.userDensity = newDensity;
0302:       }
0303:     } else if (e.touches.length === 2) {
0304:       const dx = e.touches[1].clientX - e.touches[0].clientX;
0305:       const dy = e.touches[1].clientY - e.touches[0].clientY;
0306:       const dist = Math.hypot(dx, dy);
0307:       if (pinchStartDistRef.current) {
0308:         const scale = dist / Math.max(1, pinchStartDistRef.current);
0309:         const newWidth = Math.max(60, Math.min(320, Math.round(pinchStartWidthRef.current * scale)));
0310:         setWidthMs(newWidth);
0311:         if (engineRef.current) {
0312:           engineRef.current.scheduler.grainDur = newWidth / 1000;
0313:         }
0314:       }
0315:     }
0316:     // Prevent page scroll/zoom during gesture
0317:     try { e.preventDefault(); } catch {}
0318:   };
0319: 
0320:   const onTouchEnd: React.TouchEventHandler<HTMLDivElement> = () => {
0321:     setTouchActive(false);
0322:     pinchStartDistRef.current = null;
0323:   };
0324: 
0325:   return (
0326:     <div className={`h-full flex flex-col p-8 overflow-hidden font-mono relative ${motionClass}`}>
0327:       <header className="flex justify-between items-end text-[9px] opacity-40 mb-8 shrink-0 tracking-[0.3em]">
0328:         <div className={`flex flex-col ${motionClass}`}>
0329:           <span>MODE: PREPARED_ROOM</span>
0330:           <span>STEP: [0{currentStep + 1}/08]</span>
0331:         </div>
0332:         <div className={`text-right ${motionClass}`}><span>FRAGMENTS: {fragments.length}</span></div>
0333:       </header>
0334:       <div className={`text-[9px] opacity-60 uppercase tracking-[0.2em] mb-2 tabular-nums ${motionClass}`}>
0335:         MEM_DIAG: [ BUF:{diag.bufFill}% ] [ GRAIN:{diag.grainRate}HZ ] [ RMS:{diag.rms} ] [ LAST_GHOST:{diag.lastGhost} ]
0336:       </div>
0337:       <div className="flex-1 relative border border-current border-opacity-5 bg-black/5 overflow-hidden">
0338:         {fragments.map((f, i) => (
0339:           <div key={i} className={`absolute transition-all whitespace-nowrap ${motionClass}`} style={{ left: `${f.x}%`, top: `${f.y}%`, opacity: f.opacity, fontSize: '10px' }}>
0340:             [ {f.content} ]
0341:           </div>
0342:         ))}
0343:         {/* Touch field overlay */}
0344:         <div
0345:           className="absolute inset-0 z-20"
0346:           style={{ touchAction: 'none' as any }}
0347:           onTouchStart={onTouchStart}
0348:           onTouchMove={onTouchMove}
0349:           onTouchEnd={onTouchEnd}
0350:           onTouchCancel={onTouchEnd}
0351:         />
0352:         {/* Touch diagnostics */}
0353:         <div className={`absolute left-2 bottom-2 text-[9px] opacity-60 uppercase tracking-[0.2em] tabular-nums ${motionClass}`}>
0354:           TCH_DIAG: [ WIDTH:{widthMs}MS ] [ TILT:{tilt.toFixed(2)} ] [ DENS:{density.toFixed(2)} ] [ {touchActive ? 'ACTIVE' : 'IDLE'} ]
0355:         </div>
0356:       </div>
0357:       <footer className="mt-8 border-t border-current border-opacity-10 pt-6 flex justify-between items-center">
0358:         <div className="flex gap-4">
0359:           <span onClick={() => setGhostsActive(!ghostsActive)} className={`text-[10px] cursor-pointer ${ghostsActive ? 'underline' : 'opacity-40'}`}>[ GHOSTS ]</span>
0360:           <span onClick={() => setDroneActive(!droneActive)} className={`text-[10px] cursor-pointer ${droneActive ? 'underline' : 'opacity-40'}`}>[ STATIC ]</span>
0361:         </div>
0362:         <div className={`text-[9px] opacity-40 uppercase ${motionClass}`}>{statusText}</div>
0363:       </footer>
0364:     </div>
0365:   );
0366: };
0367: 
0368: export default MemoryMode;
